% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fusionRS.R
\name{fusionRS}
\alias{fusionRS}
\title{Fusion of images with different observation geometry.}
\usage{
fusionRS(x, y, na = FALSE)
}
\arguments{
\item{x}{Optical image. It could be RasterStack or RasterBrick}

\item{y}{Radar image. It could be RasterStack or RasterBrick}

\item{na}{If TRUE the NA values of the images will be omitted from the analysis.}
}
\description{
This algorithm allows to fusion images coming from different spectral sensors
(e.g., optical-optical, optical and SAR or SAR-SAR). Among many of the qualities
of this function, it is possible to obtain the contribution (%) of each variable
in the fused image.
}
\section{References}{

Tarazona et al...
}

\section{Note}{

Before executing the function, it is recommended that images coming from different
sensors or from the same sensor have a co-registration.
}

\examples{
library(ForesToolboxRS)
library(raster)
library(factoextra)

# Optical images
b1 <- raster(ncol = 100, nrow=100, val = sample(1:2e+15, 10000))
b2 <- raster(ncol = 100, nrow=100, val = sample(1:2e+15, 10000))
optical <- stack(b1,b2)
# Radar images
vv <- raster(ncol = 100, nrow=100, val = sample(1:2e+15, 10000))
vh <- raster(ncol = 100, nrow=100, val = sample(1:2e+15, 10000))
radar <- stack(vv,vh)
# Fusion
fusion <- fusionRS(x=optical, y=radar)
#plotRGB(fusion[[1]], 1,2,3, axes=F, stretch="lin",main ="Fused images")

}
